{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec47e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from IPython.core.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2503185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "      <th>dataset</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.370</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.604</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>4.471</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.737</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.804</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  duration  dataset  \\\n",
       "2191  C:/Users/Majid/Programming files/FYP/Datasets/...     3.370  RAVDESS   \n",
       "240   C:/Users/Majid/Programming files/FYP/Datasets/...     3.604  RAVDESS   \n",
       "2013  C:/Users/Majid/Programming files/FYP/Datasets/...     4.471  RAVDESS   \n",
       "1284  C:/Users/Majid/Programming files/FYP/Datasets/...     3.737  RAVDESS   \n",
       "1320  C:/Users/Majid/Programming files/FYP/Datasets/...     3.804  RAVDESS   \n",
       "\n",
       "      emotion  \n",
       "2191    angry  \n",
       "240   neutral  \n",
       "2013    angry  \n",
       "1284      sad  \n",
       "1320  neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting RAVDESS Data:\n",
    "\n",
    "paths, labels, duration = [], [], []\n",
    "\n",
    "for dirname, _, filenames in os.walk('C:/Users/Majid/Programming files/FYP/Datasets/RAVDESS'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        paths.append(os.path.join(dirname,filename))\n",
    "        \n",
    "        duration.append(round(librosa.get_duration(filename=paths[-1]),3))\n",
    "        \n",
    "        label = filename[::-1].split('_')[0][::-1]\n",
    "        \n",
    "        if label[6:8] == '01':\n",
    "            labels.append('neutral')\n",
    "        elif label[6:8] == '02':\n",
    "            labels.append('calm')\n",
    "        elif label[6:8] == '03':\n",
    "            labels.append('happy')\n",
    "        elif label[6:8] == '04':\n",
    "            labels.append('sad')\n",
    "        elif label[6:8] == '05':\n",
    "            labels.append('angry')\n",
    "        elif label[6:8] == '06':\n",
    "            labels.append('fear')\n",
    "        elif label[6:8] == '07':\n",
    "            labels.append('disgust')\n",
    "        elif label[6:8] == '08':\n",
    "            labels.append('surprise')       \n",
    "\n",
    "df_ravdess = pd.DataFrame({'path':paths,'duration': duration, 'dataset': 'RAVDESS', 'emotion':labels})\n",
    "\n",
    "df_ravdess.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d89eb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "      <th>dataset</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...</td>\n",
       "      <td>1.576</td>\n",
       "      <td>TESS</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...</td>\n",
       "      <td>1.919</td>\n",
       "      <td>TESS</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...</td>\n",
       "      <td>1.918</td>\n",
       "      <td>TESS</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...</td>\n",
       "      <td>2.462</td>\n",
       "      <td>TESS</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...</td>\n",
       "      <td>2.224</td>\n",
       "      <td>TESS</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  duration dataset  \\\n",
       "122   C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...     1.576    TESS   \n",
       "3985  C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...     1.919    TESS   \n",
       "1138  C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...     1.918    TESS   \n",
       "297   C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...     2.462    TESS   \n",
       "2542  C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...     2.224    TESS   \n",
       "\n",
       "       emotion  \n",
       "122      angry  \n",
       "3985  surprise  \n",
       "1138  surprise  \n",
       "297    disgust  \n",
       "2542  surprise  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting TESS Data:\n",
    "\n",
    "paths, labels, duration = [],[],[]\n",
    "\n",
    "for dirname, _, filenames in os.walk('C:\\\\Users\\\\Majid\\\\Programming files\\\\FYP\\\\Datasets\\\\TESS Toronto emotional speech set data'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        \n",
    "        duration.append(round(librosa.get_duration(filename=paths[-1]), 3))\n",
    "        \n",
    "        label = filename[::-1].split('_')[0][::-1]\n",
    "        labels.append(label[:-4].lower())\n",
    "\n",
    "df_tess = pd.DataFrame({'path':paths,'duration': duration, 'dataset': 'TESS', 'emotion':labels})\n",
    "\n",
    "df_tess['emotion'] = df_tess['emotion'].replace(['ps'], 'surprise')\n",
    "                  \n",
    "df_tess.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff920356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "      <th>dataset</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...</td>\n",
       "      <td>3.971</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...</td>\n",
       "      <td>4.382</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...</td>\n",
       "      <td>3.315</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...</td>\n",
       "      <td>6.080</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...</td>\n",
       "      <td>3.544</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  duration dataset  \\\n",
       "403  C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...     3.971   SAVEE   \n",
       "18   C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...     4.382   SAVEE   \n",
       "11   C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...     3.315   SAVEE   \n",
       "343  C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...     6.080   SAVEE   \n",
       "307  C:\\Users\\Majid\\Programming Files\\FYP\\Datasets\\...     3.544   SAVEE   \n",
       "\n",
       "     emotion  \n",
       "403     fear  \n",
       "18   disgust  \n",
       "11     angry  \n",
       "343      sad  \n",
       "307  neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting SAVEE data\n",
    "paths, labels, duration = [], [], []\n",
    "\n",
    "for dirname, _, filenames in os.walk('C:\\\\Users\\\\Majid\\\\Programming Files\\\\FYP\\\\Datasets\\\\SAVEE'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        \n",
    "        label = filename[::-1].split('_')[0][::-1]\n",
    "        \n",
    "        if label[:1] == 'a':\n",
    "            labels.append('angry')\n",
    "        elif label[:1] == 'd':\n",
    "            labels.append('disgust')\n",
    "        elif label[:1] == 'f':\n",
    "            labels.append('fear')\n",
    "        elif label[:1] == 'h':\n",
    "            labels.append('happy')\n",
    "        elif label[:1] == 'n':\n",
    "            labels.append('neutral')\n",
    "        elif label[:1] == 's':\n",
    "            if label[:2] == 'sa':\n",
    "                labels.append('sad')\n",
    "            else:\n",
    "                labels.append('surprise')\n",
    "\n",
    "paths = paths[1:] # to filter out 'info.txt' file\n",
    "\n",
    "for file in paths:\n",
    "    duration.append(round(librosa.get_duration(filename=file), 3)) \n",
    "\n",
    "df_savee = pd.DataFrame({'path':paths, 'duration': duration, 'dataset': 'SAVEE', 'emotion':labels})\n",
    "                  \n",
    "df_savee.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86898d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 7332 audio files. Below printed 5 random entries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "      <th>dataset</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...</td>\n",
       "      <td>1.920</td>\n",
       "      <td>TESS</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...</td>\n",
       "      <td>2.566</td>\n",
       "      <td>TESS</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...</td>\n",
       "      <td>2.444</td>\n",
       "      <td>TESS</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.403</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.470</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  duration  dataset  \\\n",
       "2849  C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...     1.920     TESS   \n",
       "2393  C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...     2.566     TESS   \n",
       "1122  C:\\Users\\Majid\\Programming files\\FYP\\Datasets\\...     2.444     TESS   \n",
       "5194  C:/Users/Majid/Programming files/FYP/Datasets/...     3.403  RAVDESS   \n",
       "6215  C:/Users/Majid/Programming files/FYP/Datasets/...     3.470  RAVDESS   \n",
       "\n",
       "       emotion  \n",
       "2849     happy  \n",
       "2393       sad  \n",
       "1122       sad  \n",
       "5194  surprise  \n",
       "6215     happy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's merge the datesets together, now that they have been formatted the same way:\n",
    "\n",
    "df = pd.concat([df_tess, df_ravdess, df_savee])\n",
    "\n",
    "# Dropping 'calm & disgust' as out the scope (also not many samples)\n",
    "df = df[df['emotion'].str.contains('disgust|calm') == False].reset_index(drop=True)\n",
    "\n",
    "print('The dataset has {} audio files. Below printed 5 random entries:'.format(df.shape[0]))\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bfe9e",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c20be2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7332 entries, 0 to 7331\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   path      7332 non-null   object \n",
      " 1   duration  7332 non-null   float64\n",
      " 2   dataset   7332 non-null   object \n",
      " 3   emotion   7332 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 229.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e9c892",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'axes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14588\\1625789641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Creating a figure with 2 subplots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Check samples distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \"\"\"\n\u001b[0;32m   1501\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfig_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1502\u001b[1;33m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[0m\u001b[0;32m   1503\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1504\u001b[0m                        \u001b[0mgridspec_kw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight_ratios\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight_ratios\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msubplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_gridspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 906\u001b[1;33m         axs = gs.subplots(sharex=sharex, sharey=sharey, squeeze=squeeze,\n\u001b[0m\u001b[0;32m    907\u001b[0m                           subplot_kw=subplot_kw)\n\u001b[0;32m    908\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maxs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\gridspec.py\u001b[0m in \u001b[0;36msubplots\u001b[1;34m(self, sharex, sharey, squeeze, subplot_kw)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sharex\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msharex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sharey\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msharey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                 axarr[row, col] = figure.add_subplot(\n\u001b[0m\u001b[0;32m    300\u001b[0m                     self[row, col], **subplot_kw)\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         if (len(args) == 1\n\u001b[1;32m--> 739\u001b[1;33m                 \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AxesBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m                 and args[0].get_subplotspec()):\n\u001b[0;32m    741\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mprops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m    227\u001b[0m             f\"module {cls.__module__!r} has no attribute {name!r}\")\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'axes'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib_inline\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# close triggers gc.collect, which can be slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mprops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m    227\u001b[0m             f\"module {cls.__module__!r} has no attribute {name!r}\")\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'pyplot'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Creating a figure with 2 subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "\n",
    "# Check samples distribution\n",
    "df.groupby(['emotion','dataset']).size().unstack().plot(kind='bar', stacked=True, ax=axes[0])\n",
    "axes[0].set_title('Distribution of audio files by target emotion and dataset', size=14)\n",
    "axes[0].set_ylabel('number of samples')\n",
    "axes[0].legend(title='Dataset')\n",
    "\n",
    "# Check duration distribution by each source using violin plots\n",
    "sns.violinplot(x=df['dataset'],y=df['duration'], linewidth=1, ax=axes[1])\n",
    "axes[1].set_xlabel('Emotion')\n",
    "axes[1].set_ylabel('Samples duration (seconds)')\n",
    "axes[1].set_title('Audio samples duration distribution for each emotion', size=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496da4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78ba9c3b",
   "metadata": {},
   "source": [
    "Had to drop digust because we cant really relate any specific emotion on the bases of recommending music playlist. As for the calm label we didnt have enough data to trarin\n",
    "\n",
    "\n",
    "Average dataset for each emotion is from 1200+ to 1000+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb16b9",
   "metadata": {},
   "source": [
    "Finally, now let's look at what is inside the audio files, picking some random samples from different targets. In particular I want to check:\n",
    "\n",
    "the waveforms\n",
    "the spectograms, with the fundamental frequency\n",
    "the Mel-frequency cepstrum components (MFCCs), as \"two-dimensional images\".\n",
    "and of course hear how they sound, using the built-in media player of python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display samples information by emotion\n",
    "# note that a random samples is generated each time the function is called\n",
    "# this is on purpose as to check different samples of each emotion every time\n",
    "\n",
    "def show_audio(emotion):\n",
    "    # create sublots\n",
    "    fig, axs = plt.subplots(nrows=1,ncols=3, figsize=(20,4))\n",
    "    # filter dataframe to emotion)\n",
    "    df_show = df.loc[df['emotion'] == emotion].reset_index(drop=True)\n",
    "    index = random.randint(0, df_show.shape[0])\n",
    "    \n",
    "    # load audio file:\n",
    "    y, sr = librosa.load(df_show.path[index], sr=16000)\n",
    "    \n",
    "    # Show waveform\n",
    "    librosa.display.waveshow(y, sr=sr, ax=axs[0])\n",
    "    axs[0].set_title('Waveform')\n",
    "    \n",
    "    # Extract fundamental frequency (f0) using a probabilistic approach\n",
    "    f0, _, _ = librosa.pyin(y, sr=sr, fmin=50, fmax=1500, frame_length=2048)\n",
    "\n",
    "    # Establish timepoint of f0 signal\n",
    "    timepoints = np.linspace(0, df_show.duration[index], num=len(f0), endpoint=False)\n",
    "    \n",
    "    # Compute short-time Fourier Transform\n",
    "    x_stft = np.abs(librosa.stft(y))\n",
    "    \n",
    "    # Apply logarithmic dB-scale to spectrogram and set maximum to 0 dB\n",
    "    x_stft = librosa.amplitude_to_db(x_stft, ref=np.max)\n",
    "    \n",
    "    # Plot STFT spectrogram\n",
    "    librosa.display.specshow(x_stft, sr=sr, x_axis=\"time\", y_axis=\"log\", ax=axs[1])\n",
    "    \n",
    "    # Plot fundamental frequency (f0) in spectrogram plot\n",
    "    axs[1].plot(timepoints, f0, color=\"cyan\", linewidth=4)\n",
    "    axs[1].set_title('Spectrogram with fundamental frequency')\n",
    "    \n",
    "    # Extract 'n_mfcc' numbers of MFCCs components - in this case 30\n",
    "    x_mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "\n",
    "    # Plot MFCCs\n",
    "    librosa.display.specshow(x_mfccs, sr=sr, x_axis=\"time\", norm=Normalize(vmin=-50, vmax=50), ax=axs[2])\n",
    "    axs[2].set_title('MFCCs')\n",
    "    \n",
    "    # Show metadata in title\n",
    "    plt.suptitle('File: {}  -  Emotion: {}'.format(df_show.path[index], df_show.emotion[index]), size=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display media player for the selected file\n",
    "    display(ipd.Audio(y, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347995d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = sorted(list(df.emotion.unique()))\n",
    "\n",
    "# Get waveforms, spectograms, mfccs and media player for each emotion\n",
    "for emotion in emotions:\n",
    "    show_audio(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable where to store the mfccs data\n",
    "mfccs = []\n",
    "\n",
    "for file in df.path:\n",
    "    # load audio file:\n",
    "    y, sr = librosa.load(file, sr=16000)\n",
    "    \n",
    "    # Extract 'n_mfcc' numbers of MFCCs components - in this case 30\n",
    "    mfccs.append(librosa.feature.mfcc(y, sr=sr, fmin=50, n_mfcc=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b96817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to resize the 2D arrays\n",
    "def resize_array(array):\n",
    "    new_matrix = np.zeros((30,150))   # Initialize the new matrix shape with an array 30X150 of zeros\n",
    "    for i in range(30):               # Iterate rows\n",
    "        for j in range(150):          # Iterate columns\n",
    "            try:                                 # the mfccs of a sample will replace the matrix of zeros, then cutting the array up to 150\n",
    "                new_matrix[i][j] = array[i][j]\n",
    "            except IndexError:                   # if mfccs of a sample is shorter than 150, then keep looping to extend lenght to 150 with 0s\n",
    "                pass\n",
    "    return new_matrix\n",
    "\n",
    "# Create a variable to store the new resized mfccs and apply function for all the extracted mfccs\n",
    "resized_mfccs = []\n",
    "\n",
    "for mfcc in mfccs:\n",
    "    resized_mfccs.append(resize_array(mfcc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d887f",
   "metadata": {},
   "source": [
    "This code defines a function called resize_array which takes a 2D numpy array as input and returns a resized version of the array with shape (30, 150). The function first initializes a new matrix with shape (30, 150) filled with zeros. It then iterates over the rows and columns of the input array and attempts to copy the values into the new matrix. If the input array is shorter than 150 columns or 30 rows, the remaining entries in the new matrix are left as zeros. Finally, the resized matrix is appended to a list called resized_mfccs.\n",
    "\n",
    "The code then iterates over a list called mfccs and applies the resize_array function to each array in the list, storing the resulting resized arrays in the resized_mfccs list.\n",
    "\n",
    "The purpose of this code is to resize a set of 2D numpy arrays, which are likely extracted from audio data and contain mel frequency cepstral coefficients (MFCCs) used for speech and sound recognition. The resized arrays are then likely to be used as inputs to a neural network model for classification or regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b047ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sublots\n",
    "fig, axs = plt.subplots(nrows=1,ncols=6, figsize=(20,3))\n",
    "\n",
    "# Select 6 random MFCCs\n",
    "for i in range(6):\n",
    "    index = random.randint(0, len(resized_mfccs))\n",
    "    \n",
    "    # Plot MFCCs\n",
    "    librosa.display.specshow(resized_mfccs[index], sr=sr, x_axis=\"time\", ax=axs[i], norm=Normalize(vmin=-50, vmax=50))\n",
    "    axs[i].set_title(str(df.emotion[index]) + ' - ' + str(df.duration[index]) + ' sec')\n",
    "\n",
    "plt.suptitle('Few MFCCs of size 30x150', size=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70190342",
   "metadata": {},
   "source": [
    "Great, the reshaping function worked as expected, cutting the MFCC spectrum of the longer samples to ~4.5 seconds and adding silence for the shorter files to reach the same length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e625b",
   "metadata": {},
   "source": [
    "Convolutional Neural Network model!\n",
    "\n",
    "Let's split the data into train, validation and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cfe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select target\n",
    "df['emotion'].replace({'angry':0,'fear':1,'happy':2,'neutral':3,'sad':4,'surprise':5}, inplace=True)\n",
    "y = df.emotion.values\n",
    "\n",
    "# Features\n",
    "X = resized_mfccs.copy()\n",
    "\n",
    "# Create train, validation and test set\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X, y, train_size=0.3, shuffle=True, random_state=0)\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_tr, y_tr, test_size=0.7, shuffle=True, random_state=0)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "x_tr = np.array([i for i in x_tr])\n",
    "x_va = np.array([i for i in x_va])\n",
    "x_te = np.array([i for i in x_te])\n",
    "\n",
    "# Plot size of data\n",
    "print(x_tr.shape)\n",
    "print(x_va.shape)\n",
    "print(x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5444ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mean = np.mean(x_tr, axis=0)\n",
    "tr_std = np.std(x_tr, axis=0)\n",
    "\n",
    "# Apply data scaling\n",
    "x_tr = (x_tr - tr_mean)/tr_std\n",
    "x_va = (x_va - tr_mean)/tr_std\n",
    "x_te = (x_te - tr_mean)/tr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163311ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_tr has a dimension of {x_tr.shape} before the manipulation.\")\n",
    "\n",
    "x_tr = x_tr[..., None]\n",
    "x_va = x_va[..., None]\n",
    "x_te = x_te[..., None]\n",
    "\n",
    "print(f\"x_tr has a dimension of {x_tr.shape} after the manipulation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.resize(x_tr, (len(x_tr), 30, 150, 1))\n",
    "x_va = np.resize(x_va, (len(x_va), 30, 150, 1))\n",
    "x_te = np.resize(x_te, (len(x_te), 30, 150, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140317f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Conv2D, BatchNormalization, Dropout, Flatten, Dense, MaxPool2D)\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# Create convolutional neural network and return summary\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=5, strides=(2, 2), activation=\"relu\", input_shape=x_tr.shape[1:]))\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size=4, strides=(2, 1), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=7, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using Adam's default learning rate\n",
    "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Create 'EarlyStopping' callback\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b502a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Train the neural network\n",
    "history = model.fit(\n",
    "    x=x_tr,\n",
    "    y=y_tr,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_va, y_va),\n",
    "    callbacks=[earlystopping_cb]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de5a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c650bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots neural network performance metrics for train and validation\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "plt.suptitle('Convolutional Netural Network with MFCCs', size=15)\n",
    "results = pd.DataFrame(history.history)\n",
    "results[[\"loss\", \"val_loss\"]].plot(ax=axs[0])\n",
    "axs[0].set_title(\"Validation loss {:.3f} (mean last 3)\".format(np.mean(history.history[\"val_loss\"][-3:])))\n",
    "results[[\"accuracy\", \"val_accuracy\"]].plot(ax=axs[1])\n",
    "axs[1].set_title(\"Validation accuracy {:.3f} (mean last 3)\".format(np.mean(history.history[\"val_accuracy\"][-3:])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a062afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_te, accuracy_te = model.evaluate(x_te, y_te)\n",
    "\n",
    "print(\"Test loss: {:.2f}\".format(loss_te))\n",
    "print(\"Test accuracy: {:.2f}%\".format(100 * accuracy_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd87982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test set predictions\n",
    "predictions = model.predict(x_te)\n",
    "\n",
    "pred = []\n",
    "\n",
    "for i in predictions:\n",
    "    pred.append(np.argmax(i))\n",
    "    \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "labels = {'angry':0,'fear':1,'happy':2,'neutral':3,'sad':4,'surprise':5}\n",
    "\n",
    "def plot_confusion_matrices(y_true, y_pred):\n",
    "\n",
    "    # Create two subplots\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    # Plots the standard confusion matrix\n",
    "    ax1.set_title(\"Confusion Matrix (counts)\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=labels, ax=ax1)\n",
    "\n",
    "    # Plots the normalized confusion matrix\n",
    "    ax2.set_title(\"Confusion Matrix (ratios)\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=labels, normalize=\"true\", ax=ax2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrices(y_te, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
