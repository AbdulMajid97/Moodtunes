{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec47e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from IPython.core.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2503185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "      <th>dataset</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.370</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.070</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.904</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.570</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>C:/Users/Majid/Programming files/FYP/Datasets/...</td>\n",
       "      <td>3.570</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  duration  dataset  \\\n",
       "357   C:/Users/Majid/Programming files/FYP/Datasets/...     3.370  RAVDESS   \n",
       "294   C:/Users/Majid/Programming files/FYP/Datasets/...     3.070  RAVDESS   \n",
       "1904  C:/Users/Majid/Programming files/FYP/Datasets/...     3.904  RAVDESS   \n",
       "2387  C:/Users/Majid/Programming files/FYP/Datasets/...     3.570  RAVDESS   \n",
       "2284  C:/Users/Majid/Programming files/FYP/Datasets/...     3.570  RAVDESS   \n",
       "\n",
       "       emotion  \n",
       "357   surprise  \n",
       "294   surprise  \n",
       "1904   disgust  \n",
       "2387   disgust  \n",
       "2284      calm  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting RAVDESS Data:\n",
    "\n",
    "paths, labels, duration = [], [], []\n",
    "\n",
    "for dirname, _, filenames in os.walk('C:/Users/Majid/Programming files/FYP/Datasets/RAVDESS'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        paths.append(os.path.join(dirname,filename))\n",
    "        \n",
    "        duration.append(round(librosa.get_duration(filename=paths[-1]),3))\n",
    "        \n",
    "        label = filename[::-1].split('_')[0][::-1]\n",
    "        \n",
    "        if label[6:8] == '01':\n",
    "            labels.append('neutral')\n",
    "        elif label[6:8] == '02':\n",
    "            labels.append('calm')\n",
    "        elif label[6:8] == '03':\n",
    "            labels.append('happy')\n",
    "        elif label[6:8] == '04':\n",
    "            labels.append('sad')\n",
    "        elif label[6:8] == '05':\n",
    "            labels.append('angry')\n",
    "        elif label[6:8] == '06':\n",
    "            labels.append('fear')\n",
    "        elif label[6:8] == '07':\n",
    "            labels.append('disgust')\n",
    "        elif label[6:8] == '08':\n",
    "            labels.append('surprise')       \n",
    "\n",
    "df_ravdess = pd.DataFrame({'path':paths,'duration': duration, 'dataset': 'RAVDESS', 'emotion':labels})\n",
    "\n",
    "df_ravdess.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting TESS Data:\n",
    "\n",
    "paths, labels, duration = [],[],[]\n",
    "\n",
    "for dirname, _, filenames in os.walk('C:\\\\Users\\\\Majid\\\\Programming files\\\\FYP\\\\Datasets\\\\TESS Toronto emotional speech set data'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        \n",
    "        duration.append(round(librosa.get_duration(filename=paths[-1]), 3))\n",
    "        \n",
    "        label = filename[::-1].split('_')[0][::-1]\n",
    "        labels.append(label[:-4].lower())\n",
    "\n",
    "df_tess = pd.DataFrame({'path':paths,'duration': duration, 'dataset': 'TESS', 'emotion':labels})\n",
    "\n",
    "df_tess['emotion'] = df_tess['emotion'].replace(['ps'], 'surprise')\n",
    "                  \n",
    "df_tess.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff920356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting SAVEE data\n",
    "paths, labels, duration = [], [], []\n",
    "\n",
    "for dirname, _, filenames in os.walk('C:\\\\Users\\\\Majid\\\\Programming files\\\\FYP\\\\Datasets\\\\SAVEE'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        \n",
    "        label = filename[::-1].split('_')[0][::-1]\n",
    "        \n",
    "        if label[:1] == 'a':\n",
    "            labels.append('angry')\n",
    "        elif label[:1] == 'd':\n",
    "            labels.append('disgust')\n",
    "        elif label[:1] == 'f':\n",
    "            labels.append('fear')\n",
    "        elif label[:1] == 'h':\n",
    "            labels.append('happy')\n",
    "        elif label[:1] == 'n':\n",
    "            labels.append('neutral')\n",
    "        elif label[:1] == 's':\n",
    "            if label[:2] == 'sa':\n",
    "                labels.append('sad')\n",
    "            else:\n",
    "                labels.append('surprise')\n",
    "\n",
    "for file in paths:\n",
    "    duration.append(round(librosa.get_duration(filename=file), 3)) \n",
    "\n",
    "df_savee = pd.DataFrame({'path':paths, 'duration': duration, 'dataset': 'SAVEE', 'emotion':labels})\n",
    "                  \n",
    "df_savee.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ffb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting CREMA-D Dataset:\n",
    "\n",
    "paths, labels, duration = [],[],[]\n",
    "\n",
    "for dirname, _, filenames in os.walk('C:\\\\Users\\\\Majid\\\\Programming files\\\\FYP\\\\Datasets\\\\CREMA-D\\\\AudioWAV'):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        paths.append(os.path.join(dirname,filename))\n",
    "        \n",
    "        label = filename.split(\"_\")\n",
    "        \n",
    "        if label[2] == 'SAD':\n",
    "            labels.append('sad')\n",
    "        elif label[2] == 'ANG':\n",
    "            labels.append('angry')\n",
    "        elif label[2] == 'DIS':\n",
    "            labels.append('disgust')\n",
    "        elif label[2] == 'FEA':\n",
    "            labels.append('fear')\n",
    "        elif label[2] == 'HAP':\n",
    "            labels.append('happy')\n",
    "        elif label[2] == 'NEU':\n",
    "            labels.append('neutral')\n",
    "        else:\n",
    "            labels.append('Unknown')\n",
    "            \n",
    "for file in paths:\n",
    "    duration.append(round(librosa.get_duration(filename=file), 3)) \n",
    "\n",
    "\n",
    "df_crema = pd.DataFrame({'path':paths, 'duration': duration, 'dataset': 'CREMA-D', 'emotion':labels})\n",
    "                  \n",
    "df_crema.sample(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86898d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge the datesets together, now that they have been formatted the same way:\n",
    "\n",
    "df = pd.concat([df_tess, df_ravdess, df_savee])\n",
    "\n",
    "# Dropping 'calm' as out the scope (also not many samples)\n",
    "df = df[df['emotion'].str.contains('disgust|calm') == False].reset_index(drop=True)\n",
    "\n",
    "print('The dataset has {} audio files. Below printed 5 random entries:'.format(df.shape[0]))\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bfe9e",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Creating a figure with 2 subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "\n",
    "# Check samples distribution\n",
    "df.groupby(['emotion','dataset']).size().unstack().plot(kind='bar', stacked=True, ax=axes[0])\n",
    "axes[0].set_title('Distribution of audio files by target emotion and dataset', size=14)\n",
    "axes[0].set_ylabel('number of samples')\n",
    "axes[0].legend(title='Dataset')\n",
    "\n",
    "# Check duration distribution by each source using violin plots\n",
    "sns.violinplot(x=df['dataset'],y=df['duration'], linewidth=1, ax=axes[1])\n",
    "axes[1].set_xlabel('Emotion')\n",
    "axes[1].set_ylabel('Samples duration (seconds)')\n",
    "axes[1].set_title('Audio samples duration distribution for each emotion', size=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba9c3b",
   "metadata": {},
   "source": [
    "Had to drop digust because we cant really relate any specific emotion on the bases of recommending music playlist. As for the calm label we didnt have enough data to trarin\n",
    "\n",
    "\n",
    "Average dataset for each emotion is from 1200+ to 1000+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb16b9",
   "metadata": {},
   "source": [
    "Finally, now let's look at what is inside the audio files, picking some random samples from different targets. In particular I want to check:\n",
    "\n",
    "the waveforms\n",
    "the spectograms, with the fundamental frequency\n",
    "the Mel-frequency cepstrum components (MFCCs), as \"two-dimensional images\".\n",
    "and of course hear how they sound, using the built-in media player of python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display samples information by emotion\n",
    "# note that a random samples is generated each time the function is called\n",
    "# this is on purpose as to check different samples of each emotion every time\n",
    "\n",
    "def show_audio(emotion):\n",
    "    # create sublots\n",
    "    fig, axs = plt.subplots(nrows=1,ncols=3, figsize=(20,4))\n",
    "    # filter dataframe to emotion)\n",
    "    df_show = df.loc[df['emotion'] == emotion].reset_index(drop=True)\n",
    "    index = random.randint(0, df_show.shape[0])\n",
    "    \n",
    "    # load audio file:\n",
    "    y, sr = librosa.load(df_show.path[index], sr=16000)\n",
    "    \n",
    "    # Show waveform\n",
    "    librosa.display.waveshow(y, sr=sr, ax=axs[0])\n",
    "    axs[0].set_title('Waveform')\n",
    "    \n",
    "    # Extract fundamental frequency (f0) using a probabilistic approach\n",
    "    f0, _, _ = librosa.pyin(y, sr=sr, fmin=50, fmax=1500, frame_length=2048)\n",
    "\n",
    "    # Establish timepoint of f0 signal\n",
    "    timepoints = np.linspace(0, df_show.duration[index], num=len(f0), endpoint=False)\n",
    "    \n",
    "    # Compute short-time Fourier Transform\n",
    "    x_stft = np.abs(librosa.stft(y))\n",
    "    \n",
    "    # Apply logarithmic dB-scale to spectrogram and set maximum to 0 dB\n",
    "    x_stft = librosa.amplitude_to_db(x_stft, ref=np.max)\n",
    "    \n",
    "    # Plot STFT spectrogram\n",
    "    librosa.display.specshow(x_stft, sr=sr, x_axis=\"time\", y_axis=\"log\", ax=axs[1])\n",
    "    \n",
    "    # Plot fundamental frequency (f0) in spectrogram plot\n",
    "    axs[1].plot(timepoints, f0, color=\"cyan\", linewidth=4)\n",
    "    axs[1].set_title('Spectrogram with fundamental frequency')\n",
    "    \n",
    "    # Extract 'n_mfcc' numbers of MFCCs components - in this case 30\n",
    "    x_mfccs = librosa.feature.mfcc(y, sr=sr, n_mfcc=20)\n",
    "\n",
    "    # Plot MFCCs\n",
    "    librosa.display.specshow(x_mfccs, sr=sr, x_axis=\"time\", norm=Normalize(vmin=-50, vmax=50), ax=axs[2])\n",
    "    axs[2].set_title('MFCCs')\n",
    "    \n",
    "    # Show metadata in title\n",
    "    plt.suptitle('File: {}  -  Emotion: {}'.format(df_show.path[index], df_show.emotion[index]), size=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display media player for the selected file\n",
    "    display(ipd.Audio(y, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347995d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = sorted(list(df.emotion.unique()))\n",
    "\n",
    "# Get waveforms, spectograms, mfccs and media player for each emotion\n",
    "for emotion in emotions:\n",
    "    show_audio(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable where to store the mfccs data\n",
    "mfccs = []\n",
    "\n",
    "for file in df.path:\n",
    "    # load audio file:\n",
    "    y, sr = librosa.load(file, sr=16000)\n",
    "    \n",
    "    # Extract 'n_mfcc' numbers of MFCCs components - in this case 30\n",
    "    mfccs.append(librosa.feature.mfcc(y, sr=sr, fmin=50, n_mfcc=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b96817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to resize the 2D arrays\n",
    "def resize_array(array):\n",
    "    new_matrix = np.zeros((30,150))   # Initialize the new matrix shape with an array 30X150 of zeros\n",
    "    for i in range(30):               # Iterate rows\n",
    "        for j in range(150):          # Iterate columns\n",
    "            try:                                 # the mfccs of a sample will replace the matrix of zeros, then cutting the array up to 150\n",
    "                new_matrix[i][j] = array[i][j]\n",
    "            except IndexError:                   # if mfccs of a sample is shorter than 150, then keep looping to extend lenght to 150 with 0s\n",
    "                pass\n",
    "    return new_matrix\n",
    "\n",
    "# Create a variable to store the new resized mfccs and apply function for all the extracted mfccs\n",
    "resized_mfccs = []\n",
    "\n",
    "for mfcc in mfccs:\n",
    "    resized_mfccs.append(resize_array(mfcc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d887f",
   "metadata": {},
   "source": [
    "This code defines a function called resize_array which takes a 2D numpy array as input and returns a resized version of the array with shape (30, 150). The function first initializes a new matrix with shape (30, 150) filled with zeros. It then iterates over the rows and columns of the input array and attempts to copy the values into the new matrix. If the input array is shorter than 150 columns or 30 rows, the remaining entries in the new matrix are left as zeros. Finally, the resized matrix is appended to a list called resized_mfccs.\n",
    "\n",
    "The code then iterates over a list called mfccs and applies the resize_array function to each array in the list, storing the resulting resized arrays in the resized_mfccs list.\n",
    "\n",
    "The purpose of this code is to resize a set of 2D numpy arrays, which are likely extracted from audio data and contain mel frequency cepstral coefficients (MFCCs) used for speech and sound recognition. The resized arrays are then likely to be used as inputs to a neural network model for classification or regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b047ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sublots\n",
    "fig, axs = plt.subplots(nrows=1,ncols=6, figsize=(20,3))\n",
    "\n",
    "# Select 6 random MFCCs\n",
    "for i in range(6):\n",
    "    index = random.randint(0, len(resized_mfccs))\n",
    "    \n",
    "    # Plot MFCCs\n",
    "    librosa.display.specshow(resized_mfccs[index], sr=sr, x_axis=\"time\", ax=axs[i], norm=Normalize(vmin=-50, vmax=50))\n",
    "    axs[i].set_title(str(df.emotion[index]) + ' - ' + str(df.duration[index]) + ' sec')\n",
    "\n",
    "plt.suptitle('Few MFCCs of size 30x150', size=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70190342",
   "metadata": {},
   "source": [
    "Great, the reshaping function worked as expected, cutting the MFCC spectrum of the longer samples to ~4.5 seconds and adding silence for the shorter files to reach the same length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e625b",
   "metadata": {},
   "source": [
    "Convolutional Neural Network model!\n",
    "\n",
    "Let's split the data into train, validation and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cfe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select target\n",
    "df['emotion'].replace({'angry':0,'fear':1,'happy':2,'neutral':3,'sad':4,'surprise':5}, inplace=True)\n",
    "y = df.emotion.values\n",
    "\n",
    "# Features\n",
    "X = resized_mfccs.copy()\n",
    "\n",
    "# Create train, validation and test set\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X, y, train_size=0.3, shuffle=True, random_state=0)\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_tr, y_tr, test_size=0.7, shuffle=True, random_state=0)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "x_tr = np.array([i for i in x_tr])\n",
    "x_va = np.array([i for i in x_va])\n",
    "x_te = np.array([i for i in x_te])\n",
    "\n",
    "# Plot size of data\n",
    "print(x_tr.shape)\n",
    "print(x_va.shape)\n",
    "print(x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5444ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mean = np.mean(x_tr, axis=0)\n",
    "tr_std = np.std(x_tr, axis=0)\n",
    "\n",
    "# Apply data scaling\n",
    "x_tr = (x_tr - tr_mean)/tr_std\n",
    "x_va = (x_va - tr_mean)/tr_std\n",
    "x_te = (x_te - tr_mean)/tr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163311ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_tr has a dimension of {x_tr.shape} before the manipulation.\")\n",
    "\n",
    "x_tr = x_tr[..., None]\n",
    "x_va = x_va[..., None]\n",
    "x_te = x_te[..., None]\n",
    "\n",
    "print(f\"x_tr has a dimension of {x_tr.shape} after the manipulation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.resize(x_tr, (len(x_tr), 30, 150, 1))\n",
    "x_va = np.resize(x_va, (len(x_va), 30, 150, 1))\n",
    "x_te = np.resize(x_te, (len(x_te), 30, 150, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140317f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Conv2D, BatchNormalization, Dropout, Flatten, Dense, MaxPool2D)\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# Create convolutional neural network and return summary\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=5, strides=(2, 2), activation=\"relu\", input_shape=x_tr.shape[1:]))\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size=4, strides=(2, 1), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=7, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using Adam's default learning rate\n",
    "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Create 'EarlyStopping' callback\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b502a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Train the neural network\n",
    "history = model.fit(\n",
    "    x=x_tr,\n",
    "    y=y_tr,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_va, y_va),\n",
    "    callbacks=[earlystopping_cb]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de5a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c650bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots neural network performance metrics for train and validation\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "plt.suptitle('Convolutional Netural Network with MFCCs', size=15)\n",
    "results = pd.DataFrame(history.history)\n",
    "results[[\"loss\", \"val_loss\"]].plot(ax=axs[0])\n",
    "axs[0].set_title(\"Validation loss {:.3f} (mean last 3)\".format(np.mean(history.history[\"val_loss\"][-3:])))\n",
    "results[[\"accuracy\", \"val_accuracy\"]].plot(ax=axs[1])\n",
    "axs[1].set_title(\"Validation accuracy {:.3f} (mean last 3)\".format(np.mean(history.history[\"val_accuracy\"][-3:])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a062afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_te, accuracy_te = model.evaluate(x_te, y_te)\n",
    "\n",
    "print(\"Test loss: {:.2f}\".format(loss_te))\n",
    "print(\"Test accuracy: {:.2f}%\".format(100 * accuracy_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd87982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test set predictions\n",
    "predictions = model.predict(x_te)\n",
    "\n",
    "pred = []\n",
    "\n",
    "for i in predictions:\n",
    "    pred.append(np.argmax(i))\n",
    "    \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "labels = {'angry':0,'fear':1,'happy':2,'neutral':3,'sad':4,'surprise':5}\n",
    "\n",
    "def plot_confusion_matrices(y_true, y_pred):\n",
    "\n",
    "    # Create two subplots\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    # Plots the standard confusion matrix\n",
    "    ax1.set_title(\"Confusion Matrix (counts)\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=labels, ax=ax1)\n",
    "\n",
    "    # Plots the normalized confusion matrix\n",
    "    ax2.set_title(\"Confusion Matrix (ratios)\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=labels, normalize=\"true\", ax=ax2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrices(y_te, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efc58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d98b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f2cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c4d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ae459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
